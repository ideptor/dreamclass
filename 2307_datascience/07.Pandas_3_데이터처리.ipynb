{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce189546-8e43-4279-9d9a-8543a7135cf0",
   "metadata": {},
   "source": [
    "# Pandas 데이터 처리\n",
    "- 요약과 통계연산\n",
    "- 함수적용 (map, apply)\n",
    "- agg()\n",
    "- 손실데이터처리\n",
    "- 데이터 결합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a1930-7eaa-4cf9-abf4-ab7d4a801184",
   "metadata": {},
   "source": [
    "# 요약과 통계연산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de1fe25-68d7-468f-89bd-932faa4135bd",
   "metadata": {},
   "source": [
    "판다스(Pandas) 데이터프레임은 데이터를 효율적으로 `요약`하고 `통계 연산`을 수행하는 다양한 기능을 제공합니다.  \n",
    "이를 통해 데이터를 빠르게 탐색하고 데이터의 분포, 중심 경향성, 상관 관계 등을 파악할 수 있습니다.  \n",
    "주요한 요약 및 통계 연산에 대한 설명은 다음과 같습니다:\n",
    "\n",
    "1. 데이터프레임의 기본 정보 확인하기\n",
    "\n",
    "|이름|설명|\n",
    "|--|--|\n",
    "|head() 및 tail()| 데이터프레임의 처음 몇 개 또는 마지막 몇 개 행을 확인합니다.|\n",
    "|info()| 데이터프레임의 기본 정보를 확인합니다. 열의 이름, 데이터 타입, 누락된 값의 개수 등을 출력합니다.|\n",
    "|describe()| 데이터프레임의 기술 통계 요약을 제공합니다. 수치형 열에 대한 개수, 평균, 표준 편차, 최소값, 백분위수 등을 출력합니다.|\n",
    "\n",
    "2. 열별 요약 통계 연산\n",
    "\n",
    "|이름|설명|\n",
    "|--|--|\n",
    "|mean(), median(), min(), max()| 각 열의 평균, 중앙값, 최소값, 최대값을 계산합니다.|\n",
    "|sum()| 각 열의 합을 계산합니다.|\n",
    "|std()| 각 열의 표준 편차를 계산합니다.|\n",
    "|count()| 각 열의 비누락값(NaN)이 아닌 값의 개수를 계산합니다.|\n",
    "\n",
    "\n",
    "3. 행별 요약 통계 연산\n",
    "\n",
    "|이름|설명|\n",
    "|--|--|\n",
    "|sum(axis=1)| 각 행의 합을 계산합니다.|\n",
    "|mean(axis=1)| 각 행의 평균을 계산합니다.|\n",
    "|median(axis=1)| 각 행의 중앙값을 계산합니다.|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a724346-9073-41c4-b12c-2500041dc7fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "head(), tail(), info(), describe(), \n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 생성\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "        'Age': [None, 30, 35, 28],\n",
    "        'Gender': ['Female', 'Male', 'Male', 'Male'],\n",
    "        'Height': [165, 180, 175, 170]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02eb843-8788-494a-92ef-4fe084691bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec105f-a5af-489a-a738-a117728bfb64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a9b92-f572-47d6-9244-7d87eb94df2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "idxmax(), idxmin(), cumsum(),\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 생성\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "        'Age': [25, 30, 35, 21],\n",
    "        'Gender': ['Female', 'Male', 'Male', 'Male'],\n",
    "        'Height': [165, 180, None, 170]}\n",
    "df = pd.DataFrame(data, index=list(\"ABCD\"))\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb43d095-722b-4bb2-81a4-e689dec226e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.Age.sort_values(ascending=False))\n",
    "df.Age.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9262329e-9b1b-4382-87ad-d949c25d2652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.Age.sort_values())\n",
    "df.Age.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72890f-43e8-476c-b283-8efc36783796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = pd.concat([df.Age, df.Age.cumsum()], axis=1)\n",
    "df1.columns = [\"Age\", \"cumsum\"]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd92595-0b67-46d5-b3ed-8176939ccd21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 수치형 데이터로만 이루어진 Dataframe 에도 적용 가능\n",
    "df1= df[[\"Age\", \"Height\"]]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d0fea-ebca-464b-a501-8e73d13f49af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5f6b04-0fb4-416a-9765-af812eaf1413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fc781b-939f-40f5-b5f8-6442640b4007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.Age.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0562cb1-d680-4739-8364-578602f00f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 가장 나이가 많은 사람은 누구인가?\n",
    "df.loc[df.Age.idxmax(), \"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e89797-1f1a-4019-8f0c-7c5170a42afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df.Age.idxmax()][\"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd4200-ec49-4906-b6d6-bb7a050fc4df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df.Age.idxmax()].Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a19e4ab-acdd-4f04-b67c-eb48f8063b66",
   "metadata": {},
   "source": [
    "# 함수적용 (map)\n",
    "\n",
    "판다스(Pandas)의 DataFrame에서 `map()` 메서드는 Series에 적용된 값에 대해   \n",
    "지정된 사전(dict)이나 함수를 사용하여 각 값에 대한 변환을 수행하는 기능을 제공합니다.   \n",
    "map() 메서드는 주로 특정 열의 값을 다른 값으로 매핑하거나 변환하는데 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3c89d9-12fc-4bef-901b-b1d18666065f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# '성별' 열의 값에 매핑을 적용하여 숫자로 변환\n",
    "#  Gender 컬럼의 Female은 0, Male은 1로 변환\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 생성\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "        'Age': [25, 30, 35, None],\n",
    "        'Gender': ['Female', 'Male', 'Male', 'Male'],\n",
    "        'Height': [165, 180, 175, 170]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, index=list(\"ABCD\"))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70cb119-2aae-4fb9-a9e7-4fb1bad0c83c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gender_mapping = {'Female': 0, 'Male': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adbfc48-39ee-4654-978c-72e776cde553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [참고] dictionary 활용\n",
    "x = \"Female\"\n",
    "print(gender_mapping[x])\n",
    "print(gender_mapping.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e4c33-4513-4dae-8501-384611be9d21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.Gender.map(gender_mapping.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794eec43-f78a-4c56-9229-cffc88f3f92a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da188a3-a3db-4041-a90e-c29bd388f4c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Gender2'] = df.Gender.map(gender_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f19011-2659-4709-9373-63e646c794b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lambda 적용\n",
    "df.Gender.map(lambda x: 0 if x == \"Female\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1768e4-6987-4a53-bac3-d2762f13aaa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "    return 0 if x == \"Female\" else 1    # (x==\"Female\")? 1: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1349ed8a-9d2e-49d7-8284-f7b8ab342d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.Gender.map(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6b84f9-5b6e-43d4-b1c3-0fa5bc707f87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.Gender.map(lambda x: 0 if x == \"Female\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dcea0a-3610-4d9c-82e2-569c2a8c5b46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lambda 추가 예제\n",
    "print(df.Age)\n",
    "print(df.Age.map(lambda x: x + 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0d460-3f1a-439e-b35b-e067a2f97802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df)\n",
    "import numpy as np\n",
    "pd.Series(\n",
    "    np.where(df.Gender==\"Female\", 0, 1),\n",
    "    index=df.index\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08be3ee4-d5d4-4649-a814-e0a8188bb834",
   "metadata": {},
   "source": [
    "이번에는 apply 함수에 대해서 알아보도록 하겠습니다.\n",
    "\n",
    "pandas의 DataFrame에서 apply() 메서드는 열(column) 또는 행(row) 단위로 함수를 적용하여 데이터를 변환하는 기능을 제공합니다. \n",
    "apply() 메서드는 특정 함수를 데이터프레임의 모든 열 또는 각 행에 적용하며, \n",
    "이를 통해 데이터의 변환, 필터링, 정제 등 다양한 작업을 수행할 수 있습니다.\n",
    "\n",
    "이중 func, axis 파라미터에 대해서 살펴보면,\n",
    "func: 적용하고자 하는 함수를 지정합니다. 사용자 정의 함수나 내장 함수 등 모두 가능합니다. 해당 함수에는 series 객체가 인자로 들어가게 됩니다.\n",
    "axis: 0이면 함수가 열(column)에 적용됩니다. 1이면 함수가 행(row)에 적용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28418793-a8ab-4d7d-a96a-e778f02b831f",
   "metadata": {},
   "source": [
    "# 함수적용 (apply)\n",
    "\n",
    "pandas의 DataFrame에서 apply() 메서드는 열(column) 또는 행(row) 단위로 함수를 적용하여 데이터를 변환하는 기능을 제공합니다. apply() 메서드는 특정 함수를 데이터프레임의 모든 열 또는 각 행에 적용하며, 이를 통해 데이터의 변환, 필터링, 정제 등 다양한 작업을 수행할 수 있습니다.\n",
    "\n",
    "```python\n",
    "DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), **kwds)\n",
    "```\n",
    "\n",
    "- `func`: 적용하고자 하는 함수를 지정합니다. 사용자 정의 함수나 내장 함수 등 모두 가능합니다.\n",
    "- `axis`: 0이면 함수가 열(column)에 적용됩니다. 1이면 함수가 행(row)에 적용됩니다.\n",
    "- `raw`: True이면 행 또는 열을 배열로 전달하고, False이면 Series로 전달합니다.\n",
    "- `result_type`: 반환되는 결과의 데이터 타입을 지정합니다.\n",
    "- `args`: 함수에 추가적인 인자를 전달할 경우 사용합니다.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e66d281a-a5db-423d-8c05-ea548dfc1ebe",
   "metadata": {},
   "source": [
    "예제를 통해 알아보도록 하겠습니다.\n",
    "이번 예제는 각 열에 대해 최대값을마지막 행에 삽입하는 것입니다.\n",
    "일단 3행 5열의 데이터 프레임을 만들어보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b73136-34e0-4287-ae93-91967069b1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "각 열의 최대값을 마지막 행에 삽입\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 생성\n",
    "data = np.random.choice(range(1,16), 15, replace=False).reshape(3,5)\n",
    "df = pd.DataFrame(data, index=\"R1 R2 R3\".split(), columns=\"C1 C2 C3 C4 C5\".split())\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "716e8ccf-9a89-4e6f-a375-52451cd7216f",
   "metadata": {},
   "source": [
    "apply() 함수는 데이터 프레임에서 호출되며\n",
    "인자로 들어가는 함수는 Series 객체를 파라미터로 받으며 호출이 됩니다.\n",
    "\n",
    "그래서 apply에 인자로 넣어주는 함수를 \n",
    "아래와 같이 Series를 받아서 그중에 max()를 호출하는 함수를 만들어서\n",
    "find_max라는 이름으로 정의하였습니다.\n",
    "\n",
    "그런후 df.apply를 호출하면서 해당 함수를 호출하였습니다.\n",
    "이때 열 단위로 계산하기 위하여 axis=0으로 넣어주었는데,\n",
    "axis파라미터 의 default value는 0 이므로\n",
    "넣어주지 않아도 무방합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c3ee30-cc76-4945-992d-9fdea6052074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 각 열에 대해 최대값을 찾는 함수 정의\n",
    "def find_max(s: pd.Series):\n",
    "    return s.max()\n",
    "\n",
    "df.apply(find_max, axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91505110-e7b1-433e-a878-6c4960357476",
   "metadata": {},
   "source": [
    "위의 예제에서 apply함수를 호출하면\n",
    "데이터프레임 df의 각 열들에 해당하는 시리즈 객체들을 findx_max에 넣어주고\n",
    "컬럼이름을 인덱스 find_max()의 리턴값을 밸류로 하는 시리지 객체를 만들어 줍니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e931bef5-4feb-484b-9605-43233571ff31",
   "metadata": {
    "tags": []
   },
   "source": [
    "# apply 동작 개요 (axis=0)\n",
    "func=find_max\n",
    "pd.Series(\n",
    "    [func(df[x]) for x in df.columns],\n",
    "    index = df.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "acc61a83-9e0f-4813-ac7f-56aa9d46fa5f",
   "metadata": {},
   "source": [
    "위에서 생성된 각 열의 max값드르이 series를 마지막행에 추가해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfd04fd-6544-4207-88bd-bee48a87d73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58b4f05b-d3a8-4b24-927d-91c3af4e4300",
   "metadata": {},
   "source": [
    "데이터 프레임에 행을 추가 하기 위해서는\n",
    "loc[] 인덱서에 삽입할 행의 index를 를 넣어주고 Series 객체를 어사인하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43eb6a-f656-4568-9575-a9b00b2b9b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[\"MAX\"] = df.apply(find_max, axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e12a826b-0867-4fef-aae3-253d8c09d865",
   "metadata": {},
   "source": [
    "그러면 위와 같이 마지막 행에 MAX 라는 인덱스로 각 열의 최대값이 추가된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ad43bb6-349e-4f0b-aa54-39b7535fbe94",
   "metadata": {},
   "source": [
    "위의 예제를 lambda를 활용해서 다시 정리해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826136fb-668e-439f-9d69-3114fb8e7c37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[\"MAX\"] = df.apply(lambda x: x.max())\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39f454d6-260b-48b4-89c7-15f7e2aad131",
   "metadata": {},
   "source": [
    "이번에는 각 행의 최대값과 최소값으 차이를 구해서 마지막 열에 추가하는 것을 진행해보도록 하겠습니다.\n",
    "우선 데이터 프레임을 만들어 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d9c80-cc61-4f1d-98d6-4ee116158d86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "각 행의 최대, 최소 차이를 마지막 열에 추가\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 생성\n",
    "data = np.random.choice(range(1,16), 15, replace=False).reshape(3,5)\n",
    "df = pd.DataFrame(data, index=\"R1 R2 R3\".split(), columns=\"C1 C2 C3 C4 C5\".split())\n",
    "df\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55c72816-297e-4f1f-b8e0-a3ebc26d297d",
   "metadata": {},
   "source": [
    "우선 각 행에서 최대값과 최소값의 차이를 계산하는 함수를 정의해보겠습니다.\n",
    "이 함수는 Series를 인자로 받아서\n",
    "최대값인 max()에서 최소값인 min()을 빼서 그 차이를 리턴하도록 하고\n",
    "max_min_diff 라는 이름으로 정의하였습니다.\n",
    "\n",
    "그리고 이 함수를 행단위로 적용하기 위해서는\n",
    "apply를 호출할때 파라미터로 axis=1 을 넣어줍니다.\n",
    "그러면 행단위로 최대값과 최소값의 차이에 대해서\n",
    "각 행의 인덱스를 인덱스로하고, 차이값을 밸류로 하는 시리즈 객체를 리턴합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba0653-64ee-43b0-b7ba-4d0bdf74e7a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 각 행에서 최대값과 최소값의 차이를 계산하는 함수 정의\n",
    "def max_min_diff(s: pd.Series):\n",
    "    return s.max() - s.min()\n",
    "\n",
    "df.apply(max_min_diff, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8bc17697-4bc4-4067-9e96-e133500882af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# apply 동작 개요 (axis=1)\n",
    "func=max_min_diff\n",
    "pd.Series(\n",
    "    [func(df.loc[idx]) for idx in df.index],\n",
    "    index = df.index\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7de86eef-08a0-48c6-9daa-766b42a06c5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "데이터 프레임에 열을 추가 하기 위해서는\n",
    "데이터프레임의 객체의 [] 에 삽입될 컬럼의 이름을 적어주고 \n",
    "Series 객체를 어사인하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a71129d-7b87-4c1c-8647-614e2089772c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"MIN_MAX_DIFF\"] = df.apply(max_min_diff, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29d4dae9-5908-4b4d-96c2-2a99de0a7a32",
   "metadata": {},
   "source": [
    "이번에는 lambda를 활용해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2382d-3ae7-4e93-a4d1-0a450d0caf2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"MIN_MAX_DIFF\"] = df.apply(lambda x: x.max() - x.min(), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39d399d5-802a-4333-bf7e-1c91055c7ee8",
   "metadata": {},
   "source": [
    "이번에는 필터링 기반으로 특정조건에 맞는 행 또는 열에 대해서만 \n",
    "apply를 적용하는 방식에 대해서 알아보도록 하겠습니다.\n",
    "\n",
    "데이터프레임에서 조건에 맞는 셀의 데이터에만 map과 apply를 적용하는 방법은  \n",
    "loc 인덱싱을 사용하여 조건을 만족하는 행과 열을 선택한 후에  \n",
    "해당 위치에 함수를 적용하면 됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984f468d-f8b2-496f-a4cd-8468dfe72965",
   "metadata": {},
   "source": [
    "## 필터링 기반 apply 적용\n",
    "\n",
    "\n",
    "데이터프레임에서 조건에 맞는 셀의 데이터에만 map과 apply를 적용하는 방법은  \n",
    "loc 인덱싱을 사용하여 조건을 만족하는 행과 열을 선택한 후에  \n",
    "해당 위치에 함수를 적용하면 됩니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b543da90-4752-4444-99d7-4314bd676923",
   "metadata": {},
   "source": [
    "우선 예제를 위한 데이터 프레임을 생성해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e4983-5ed5-4901-95de-7a23ea67ca76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 생성\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Ella'],\n",
    "    'Age': [25, 30, 35, 40, 45],\n",
    "    'City': ['New York', 'London', 'Paris', 'Berlin', 'London']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5ecff6a-882b-40cc-8d86-d1d2dc7def9d",
   "metadata": {},
   "source": [
    "Age가 35 이상인 행들의 'Age' 값을 10 증가시키는 예제입니다. \n",
    "이 경우 해당 하는 column 이 한개 이기 때문에 map()을 적용하여 해결 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238650f5-aeed-4b76-8ea7-51a7a08c4e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Age가 35 이상인 행들의 'Age' 값을 10 증가시킴 (map 적용)\n",
    "df.loc[df['Age'] >= 35, 'Age'] = df.loc[df['Age'] >= 35, 'Age'].map(lambda x: x + 10)\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ccd649e3-edd8-4092-9419-30b9fbc20882",
   "metadata": {},
   "source": [
    "몸무게가 70kg 이상인 경우에만 BMI를 계산하는 미션을 수행해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9177b369-0c6e-46f4-a0e6-bf5bc9db67b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "몸무게가 70kg 이상인 경우에만 BMI를 계산\n",
    " BMI 계산: weight / pow(height, 2)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 생성\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "        'Weight': [65, 70, 85, None],\n",
    "        'Height': [1.65, 1.8, 1.75, 1.7]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd986d-b2f1-40ef-974b-530b145bc779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df.Weight>=70, \"BMI\"] = df[df.Weight>=70].apply(\n",
    "    lambda x: np.round(x[\"Weight\"] / (x[\"Height\"])**2,1), \n",
    "    axis=1\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d49c27-4623-49db-954c-95f517a8ab1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df.Weight>=70, \"BMI\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ed04cf-4672-4bda-8765-eae1f6dc701d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[df.Weight>=70].apply(lambda x: np.round(x[\"Weight\"] / (x[\"Height\"])**2,1), axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c6cf5e7-eb19-4f03-be4f-01582259b7e5",
   "metadata": {},
   "source": [
    "위의 예제에서는 loc 인덱서에 조건식을 주어 필터링 한 후에 apply를 호출하는 방식을 적용하였는데,\n",
    "다음과 같이 apply()호출 전에 df를 loc 인덱서를 사용해서 필터링 해주지 않더라도\n",
    "최종에는 동일한 결과를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9c6120-b33c-456d-8680-92724e958bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df.Weight>=70, \"BMI\"] = df.apply(\n",
    "    lambda x: np.round(x[\"Weight\"] / (x[\"Height\"])**2,1), \n",
    "    axis=1\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c7de27a-289e-4186-8965-459a84b6c400",
   "metadata": {},
   "source": [
    "그 이유는 아래의 코드에서는 모든 행에 대해서 apply 를 적용하지만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac791776-fa37-4cd7-9c29-330a74e060f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2 = df.apply(\n",
    "    lambda x: np.round(x[\"Weight\"] / (x[\"Height\"])**2,1), \n",
    "    axis=1\n",
    ")\n",
    "s2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dc02d20-d08a-40ad-b2c8-1e60cb60283c",
   "metadata": {},
   "source": [
    "실제로 assign을 할 때에는 좌측항에 있는 index와 일치 되는 값에 대해서만\n",
    "대체되기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9580fc-7208-4272-b482-0a4774fb4be8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df.Weight>=70, \"BMI\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785569c6-37c5-47df-9ace-a82cbe4e2d18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df.Weight>=70, \"BMI\"] = s2\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5fc4da81-dfb5-4acf-bac5-66dd179c4b06",
   "metadata": {},
   "source": [
    "다만, 이경우에는 나중에 사용되지 않을 행까지 포함한 모든 행에 대해서\n",
    "apply() 연산을 수행하기 때문에\n",
    "수행속도에는 불리합니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bf8efab-2926-4800-a679-945373910847",
   "metadata": {
    "tags": []
   },
   "source": [
    "이번에는 agg() 함수를 통해서 여러개의 집계함수를 동시에 적용하는 방법에 대해서 알아보도록 하겠습니다.\n",
    "pandas에 내장된 함수는 아래와 같습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e483499-19e8-4ce4-b38b-32a718bfbc52",
   "metadata": {},
   "source": [
    "## agg()\n",
    "agg() 함수를 사용하면 여러 개의 집계 함수를 동시에 적용할 수 있으며, 그룹화된 데이터에서 원하는 다양한 집계 연산을 손쉽게 수행할 수 있습니다.\n",
    "\n",
    "내장 집계 함수:\n",
    "\n",
    "| 이름 | 기능 |\n",
    "|--|--|\n",
    "|mean()| 평균을 계산합니다.|\n",
    "|sum()| 합계를 계산합니다.|\n",
    "|min()| 최소값을 찾습니다.|\n",
    "|max()| 최대값을 찾습니다.|\n",
    "|count()| 데이터의 개수를 세어줍니다.|\n",
    "|median()| 중앙값을 계산합니다.|\n",
    "|std()| 표준편차를 계산합니다.|\n",
    "|var()| 분산을 계산합니다.|\n",
    "|quantile(q)| q-분위수를 계산합니다. (0 <= q <= 1)|\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b4fce01-d53b-404c-8d76-a4ca0fa7b7a2",
   "metadata": {},
   "source": [
    "예제를 통해서 확인해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7e9a9a7-59d4-4d2d-9d02-0b8dcf73f1c1",
   "metadata": {},
   "source": [
    "우선 예제를 위한 데이터프레임을 생성하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765e6a3-207e-423e-94a3-b6d5a2e5716c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = dict(\n",
    "    Name=\"Alice Bob Charlie David\".split(\" \"),\n",
    "    Math=np.random.randint(50,100,4),\n",
    "    Eng=np.random.randint(50,100,4),\n",
    ")\n",
    "df = pd.DataFrame(data, index=list(\"ABCD\"))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "125f978d-d3d3-4a77-9030-d31a2cc2723f",
   "metadata": {},
   "source": [
    "agg 메소드는 모든 데이터가 수치형인 데이터프레임에 대해서만 적용이 가능합니다.\n",
    "그래서 수치형 데이터인 열을 추출한 데이터 프레임을 만든후\n",
    "agg()메소드를 호출합니다.\n",
    "agg() 메소드를 호출할때 파라미터로는 호출할 집계합수를 문자열의 배열형태로 넣어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc13641e-29e6-44ce-95ea-87153ae9467c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.iloc[:,1:].agg([\"sum\", \"mean\", \"max\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c5a2ac1-5c05-4806-979c-e7872973e2d6",
   "metadata": {},
   "source": [
    "위의 예제에서 Math와 Eng의 컬럼에 대해서 \n",
    "sum, mean, max의 집계함수의 결과를 호출한것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "da04266c-fcef-4e30-8515-e0be4b031c0a",
   "metadata": {},
   "source": [
    "transpose 를 활용해서\n",
    "행 기준으로도 agg 함수를 통한 집계결과를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae22777-55db-4237-b374-24202c4082b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.iloc[:,1:].T.agg([\"sum\", \"mean\", \"max\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ac8c9a7-3da2-4815-9a9e-2db92b8c9b0b",
   "metadata": {},
   "source": [
    "agg()의 파라미터는 내장 객체 뿐 아니라 사용자정의 함수도 입력할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c566ada-9d3c-4969-b45f-837d59140e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(s):\n",
    "    mean = s.mean()\n",
    "    return (sum((s-mean)**2))**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63133ab-a391-40da-bea3-e12bcbfa8eef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.iloc[:,1:].agg([\"std\", lambda x: x.idxmax(), mean_squared_error])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0edc9be0-4924-4ff0-b217-af3218eb5d51",
   "metadata": {},
   "source": [
    "위의 코드를 실행해 보면 내장집계함수인 std, 그리고 lambda, 그리고 mean_squared_error 함수를 파라미터로 넣어주었을때\n",
    "각각의 결과가 행으로 나타나는 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e144495d-517d-466f-98e0-107e6648e14d",
   "metadata": {},
   "source": [
    "## 손실데이터 처리\n",
    "\n",
    "누락된 값(결측치)을 적절한 값으로 대체하는 것입니다.  \n",
    "판다스(Pandas)에서는 `fillna()` 메서드를 사용하여 누락된 값을 다른 값으로 채울 수 있습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe9dbc90-9f73-4391-9735-efb2a11c81b1",
   "metadata": {},
   "source": [
    "손실데이터 처리에 대해서 알아보도록 하겠습니다.\n",
    "손실데이터 처리란 누락된 값(결측치)을 적절한 값으로 대체하는 것입니다.\n",
    "판다스(Pandas)에서는 fillna() 메서드를 사용하여 누락된 값을 다른 값으로 채울 수 있습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2da3e62-5af5-4d12-838e-e119d21ba752",
   "metadata": {},
   "source": [
    "예제를 통해서 알아보도록 하겠습니다.\n",
    "우선 예제코드를 위한 데이터 프레임을 생성하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31413e2e-1284-46e4-bfcc-a5d3f6040ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 생성 (일부 값이 누락된 데이터)\n",
    "data = [\n",
    "    [1, 2, np.nan, 4, 5],\n",
    "    [10, np.nan, 30, np.nan, 50],\n",
    "    [100, 200, 300, np.nan, np.nan]\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data, \n",
    "    index=[f\"R{i}\" for i in range(len(data))],\n",
    "    columns=[f\"C{i}\" for i in range(len(data[0]))]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5c670d5-1b8c-4649-837d-21496d687987",
   "metadata": {},
   "source": [
    "위의 데이터 프레임에서 NaN이라고 되어 있는 부분은 데이터가 없는 부분이고\n",
    "결측치라고 불리우는 부분입니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f489861-064c-44cd-99a4-712b7d498b34",
   "metadata": {},
   "source": [
    "우선 데이터 프레임에 결측치가 얼마나 있는지에 알아보는 방법에 대해서 확인해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4fbc555-9746-4d57-8902-20117ab9cbd5",
   "metadata": {},
   "source": [
    "우선 df.info를 활용하는 방법입니다.\n",
    "이경우에는 각 컬럼별로 결측치가 아닌 데이터의 갯수를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8652d5-472b-4512-9495-86d529596402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e562a06-aeb2-437e-b248-9a4cfc79b6f7",
   "metadata": {},
   "source": [
    "그리고 다른 방법은 isna()를 호출하는 방법입니다.\n",
    "isna()는 결측치 일경우 True를 반환하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a11ddf-3194-4bd4-bed4-4a975f31a9a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89e07800-f629-4866-9d68-d273f3783786",
   "metadata": {},
   "source": [
    "이를 기반으로 판다스 내장 집계햠수인 sum()을 활용하면 \n",
    "각 행, 각 열 또는 데이터 프레임 전체에서의 결측치의 갯수를 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba65f81d-3da8-4fba-bfaa-e88adf2357b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 각 열의 결측치 갯수\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d33fe1b-b6e2-4fee-8e07-babdefc7d4f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 각 행의 결측치 갯수\n",
    "df.isna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b390717-e6d4-4ac7-b443-4094efa7b343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 전체 결측치 개수\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ff3cc44-cf79-4179-83ac-880190e30034",
   "metadata": {},
   "source": [
    "notna()는 결측치가 아닐 경우 True를 리턴합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b8aa66-0a09-4109-8d87-3e71c25232be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.notna()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1652b269-f6a7-49bd-b15e-1b77cb6ed0c7",
   "metadata": {},
   "source": [
    "결측치가 아닌 전체 데이터의 갯수를 구하는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626af8b9-b687-4735-8856-84a6bf121e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddcf755-5ac8-4abc-92ef-55938fe4919d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.notna().sum().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39d84b33-4341-4ce1-8992-a418dfaf2fb2",
   "metadata": {},
   "source": [
    "describe()를 호출해보면 count 값이 결측치가 아닌 값들의 갯수임을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd285e-f693-4380-bf54-dfcf9e5bbcd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88f023b6-7478-44f2-9033-8bcf5fb92b18",
   "metadata": {},
   "source": [
    "이번에는 fillna()를 사용하여 누락된 값을 대체하는 방법을 알아보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669dc826-1f55-404b-813f-86980519cfb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 누락된 값을 0으로 대체\n",
    "df2 = df.fillna(0)\n",
    "df2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9c3ddab-daa5-4252-96bb-451ac059a38b",
   "metadata": {},
   "source": [
    "df.fillna(0)를 호출하면 NaN 데이터가 \n",
    "fillna()를 호출할때 파라미터로 넣었던 0으로 변경된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "faa4bc54-debf-407d-b84a-d26a81ff24ee",
   "metadata": {},
   "source": [
    "fillna() 역시 원본데이터를 변경시키지는 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb60f45-db25-48e3-baae-138199c297f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19d2956c-73ec-4fa9-af22-0a2be3889830",
   "metadata": {},
   "source": [
    "원본 데이터를 변화시키기 위해서는 inplace=True 파라미터를 넣어주면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95eb3f8-dc1f-4265-a5d3-1aa82dfb6659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9bab22dc-33cf-46ef-9dd1-241f14f5808b",
   "metadata": {},
   "source": [
    "이번에는 fillna()를 활용하여 누락된 값을 각 컬럼의 평균 값으로 대체해보도록 하겟습니다.\n",
    "이때는 fillna의 파라미터에 df.mean()을 넣어주면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc4173-e60e-4645-a32f-4df637f09459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 생성 (일부 값이 누락된 데이터)\n",
    "data = [\n",
    "    [1, 2, np.nan, 4, 5],\n",
    "    [10, np.nan, 30, np.nan, 50],\n",
    "    [100, 200, 300, np.nan, np.nan]\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data, \n",
    "    index=[f\"R{i}\" for i in range(len(data))],\n",
    "    columns=[f\"C{i}\" for i in range(len(data[0]))]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e08ee-3cad-4a0d-a9a3-670ffd35dbcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 누락된 값을 각 컬럼의 평균값으로 대체\n",
    "print(\"df.mean(): \", df.mean())\n",
    "df2 = df.fillna(df.mean())\n",
    "df2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7b639f8-fe8e-41b0-9f26-320ab4edb427",
   "metadata": {},
   "source": [
    "위의 코드를 실행시켜 보면\n",
    "각 결측치가 해당 컬럼의 평균값으로 입력되었음을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d181844-7e39-42be-9de6-349ab950b06d",
   "metadata": {},
   "source": [
    "이번에는 결측치를 바로 이전의 값으로 넣는 방법을 알아보도록 하겠습니다.\n",
    "바로 이전 값으로 결측치를 채우기 위해서는\n",
    "fillna를 호출할때 method=\"ffill\" 을 파라미터로 넣어주면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5896223e-6dd0-4055-812b-b8454ac55855",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 누락된 값을 바로 앞의 값으로 대체 (forward fill)\n",
    "df2 = df.fillna(method='ffill')\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c85a5a81-0e1d-4aa8-8a53-fc5478a8e725",
   "metadata": {},
   "source": [
    "이번에는 두개 이상의 dataframe을 결합하는 방법에 대해서 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628c5e91-0406-4f5e-a61a-b3232929a334",
   "metadata": {},
   "source": [
    "# 데이터 결합하기\n",
    "\n",
    "merge()와 concat()은 판다스(Pandas)에서  \n",
    "데이터프레임을 합치는 데 사용되는 두 가지 중요한 메서드입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a16f29-2d6d-47f9-8cdf-642604c7cc81",
   "metadata": {},
   "source": [
    "**concat() 메서드:**  \n",
    "concat() 메서드는 여러 개의 데이터프레임을  \n",
    "행(axis=0) 또는 열(axis=1) 방향으로 합치는 데 사용됩니다.  \n",
    "기본적으로 데이터프레임을 단순히 연결하여 합치는 기능을 제공합니다.\n",
    "\n",
    "**concat() 메서드의 형식:**\n",
    "\n",
    "```python\n",
    "pd.concat(objs, axis=0, join='outer', ignore_index=False)\n",
    "```\n",
    "    \n",
    "- `objs`: 합치려는 데이터프레임을 리스트 형태로 전달합니다.\n",
    "- `axis`: 합치는 방향을 지정합니다. 0이면 행 방향, 1이면 열 방향입니다.\n",
    "- `join`: 합치는 방식을 지정합니다. 기본값은 'outer'로, 합집합을 반환합니다.\n",
    "- `ignore_index`: 기존 인덱스를 무시하고 새로운 인덱스를 생성하도록 지정합니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "74be0581-5d73-43c4-8a25-0f3d34113b2b",
   "metadata": {},
   "source": [
    "예제를 통해 concat 메소드의 활용방법에 대해서 알아보도록 하겠습니다.\n",
    "우선 데이터프레임 객체들을 준비해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a096d-e3f4-48ca-9a50-a23f42f5b285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "concat() 메서드의 axis 매개변수를 사용하여 \n",
    "데이터프레임을 합칠 때 방향(행 또는 열)을 지정할 수 있습니다. \n",
    "axis 매개변수에는 0 또는 1을 입력할 수 있으며, \n",
    "각각 행 방향과 열 방향을 의미합니다.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 생성\n",
    "data1 = {\n",
    "    'ID': [1, 2, 3],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie']\n",
    "}\n",
    "\n",
    "data2 = {\n",
    "    'Age': [25, 30],\n",
    "    'City': ['New York', 'London']\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data1, index=list(\"ABC\"))\n",
    "df2 = pd.DataFrame(data2, index=list(\"AC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de35990-db69-43ba-a48a-672f3ed43173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27624a18-68ad-4b90-8083-97d5ba281920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f1075a9-0d8e-4dcf-8e52-6e4302d6f180",
   "metadata": {
    "tags": []
   },
   "source": [
    "두개의 데이터 프레임을 행 방향으로 합치는 예제입니다.\n",
    "axis=0을 넣어주면 됩니다.\n",
    "axis의 기본값을 0이므로 axis 파라미터를 생략하면 0의 값이 들어가게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fefa42-795a-4e35-b9eb-32e14f31fb02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concat 메서드에서 axis=0을 사용하여 행 방향으로 합치기\n",
    "pd.concat([df1, df2], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53963033-5303-4b72-a52b-e28abe1c5ba8",
   "metadata": {},
   "source": [
    "데이터 프레임이 행 방향으로 합쳐진것을 볼 수 있으며, \n",
    "특정 칼럼에 대한 데이터가 없을 경우에는 NaN으로 채워져 있는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2225cab9-3454-4c33-a95c-49cbc90ee5bf",
   "metadata": {},
   "source": [
    "이번에는 ignore_index를 True로 하였을경우를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5810564f-d3ec-4286-8024-e61fa7c48e82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# igrnoe_index를 True로 하였을 경우\n",
    "pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3751a54-54f1-4ed9-b15f-99fc2254afff",
   "metadata": {},
   "source": [
    "이 코드를 실행하면 기존의 index인 A,B,C 값이 없어지고\n",
    "자동증가 번호로 새로이 index가 채워져 있음을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaf0c5e5-29fb-46b5-859a-66ce6b7de3a2",
   "metadata": {},
   "source": [
    "이번에는 concat을 호출할때 axis=1 을 인자로 넣어주어 \n",
    "행방향으로 병합해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47eca2e-10d5-4b27-ad55-30073d05eede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e57eb06-b990-4d24-ad11-819b7475d651",
   "metadata": {},
   "source": [
    "이경우 열방향으로 데이터프레임을 결함하며\n",
    "해당 데이터프레임의 index 기준으로 병합되는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c72333bf-db35-4c41-82a7-f2407408cb07",
   "metadata": {},
   "source": [
    "이번에는 concat을 호출할때 join 파라미터의 값을 통해서 \n",
    "inner 또는 outer join 방식을 적용하는 방법에 대해서 알아보도록 하겠습니다.\n",
    "join='outer': 기본값으로, 인덱스가 겹치지 않는 경우에는 빈 값(NaN)으로 처리되며, \n",
    "            인덱스가 겹치는 경우에는 합집합으로 합쳐집니다.\n",
    "join='inner': 인덱스가 겹치는 경우에는 교집합으로 합쳐집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903bc5d7-0483-465f-bd7c-4322430722be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "join:\n",
    "join='outer': 기본값으로, 인덱스가 겹치지 않는 경우에는 빈 값(NaN)으로 처리되며, \n",
    "            인덱스가 겹치는 경우에는 합집합으로 합쳐집니다.\n",
    "join='inner': 인덱스가 겹치는 경우에는 교집합으로 합쳐집니다.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 생성\n",
    "data1 = {\n",
    "    'ID': [1, 2, 3],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie']\n",
    "}\n",
    "\n",
    "data2 = {\n",
    "    'ID': [2, 3, 4],\n",
    "    'Age': [25, 30, 35]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data1, index=list(\"ABC\"))\n",
    "df2 = pd.DataFrame(data2, index=list(\"ABD\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71205ce1-ef36-4273-b601-d181d8912067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35027a4-85a0-4383-a108-12859106de7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c7e9e-4832-4605-9ab2-2070810bc555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concat 메서드에서 join='outer'를 사용하여 기본값으로 합치기\n",
    "pd.concat([df1, df2], axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "803c6d83-12ab-47fe-a02a-4938605fa95b",
   "metadata": {},
   "source": [
    "이경우 병합되는 모든 데이터를 포함하는 데이터 프레임이 생성되게 됩니다.\n",
    "일종의 합집합의 개념이며,\n",
    "index 기준으로 병합하였을때 값이 없는 부분에 대해서는 NaN채워지게 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e86c83-03d5-4b8a-8bc8-f0e30ef3418e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concat 메서드에서 join='inner'를 사용하여 교집합으로 합치기\n",
    "pd.concat([df1, df2], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c4db38d-7f0f-4f8b-aeff-ecd2b4d2182e",
   "metadata": {},
   "source": [
    "이 경우 공통된 index가 있는 데이터에 대해서만 포함하게 됩니다.\n",
    "일종의 교집합의 개념입니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "65e56ad3-d006-49d5-8a55-ebc2d9631c99",
   "metadata": {},
   "source": [
    "이번에는 merge() 함수로 병합하는 방법에 대해서 알아보도록 하겠습니다.\n",
    "concat이 데이터프레임의 인덱스 기준으로 병합하는 것과는 달리\n",
    "merge()는 특정 칼럼의 값을 기준으로 병합하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f48825-34cb-45af-81a3-e481f3d1ad54",
   "metadata": {},
   "source": [
    "1. merge() 메서드:\n",
    "merge() 메서드는 두 개의 데이터프레임을 특정 열(column)을 기준으로 합치는 데 사용됩니다. SQL의 JOIN 연산과 유사한 기능을 제공합니다.\n",
    "\n",
    "merge() 메서드의 형식:\n",
    "\n",
    "```python\n",
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None)\n",
    "```\n",
    "\n",
    "- `left`: 왼쪽에 있는 데이터프레임을 지정합니다.\n",
    "- `right`: 오른쪽에 있는 데이터프레임을 지정합니다.\n",
    "- `how`: 합치는 방식을 지정합니다. 기본값은 'inner'로, 교집합을 반환합니다. `outer`, `left`, `right` 등이 가능합니다.\n",
    "- `on`, `left_on`, `right_on`: 합치는 기준 열을 지정합니다.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "463261fd-d165-409b-9974-fe63120d5364",
   "metadata": {},
   "source": [
    "예제를 통해 확인해보도록 하겠습니다.\n",
    "우선 예제를 위한 데이터 프레임을 성생합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db06bd-0311-4aad-a03f-e2e4a4d6825c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 생성\n",
    "data1 = {\n",
    "    'ID': [1, 2, 3, 4],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David']\n",
    "}\n",
    "\n",
    "data2 = {\n",
    "    'ID': [3, 4, 5, 6],\n",
    "    'Age': [25, 30, 35, 40]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b2e2f-0b65-4294-98d9-b4dd95c5f727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66c310-8287-4be4-b51b-91dc300a68ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53b220c4-5e4b-4be9-b04a-d3534339a42d",
   "metadata": {},
   "source": [
    "'ID' 열을 기준으로 두 데이터프레임 합치는 방법입니다.\n",
    "첫번째와 두번째 파라미터에는 결합하고자 하는 데이터프레임을 각각 넣어주고\n",
    "on파라미터에는 합치는 기준이 되는 컬럼명을 입력합니다.\n",
    "해당 컬럼의 내용이 같은 행끼리 결합하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950294b1-1b1f-4939-9856-dfb7b20b5cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'ID' 열을 기준으로 두 데이터프레임 합치기 (inner join)\n",
    "pd.merge(df1, df2, on='ID')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f6b4093-d800-4b9f-9b9c-8945a98135d1",
   "metadata": {},
   "source": [
    "위의 코드를 실행시켜 보면, df1, df2 에 공통으로 있는 ID인 3,4 에 대해서만 최종결과가 나온느것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "812b9b78-c5ee-4ecb-946c-3d1055e4aa11",
   "metadata": {},
   "source": [
    "결합 방식에 대해서는 how 매개변수로 조정이 가능합니다.\n",
    "(아래 내용 읽기)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04459d0a-6be7-4648-b54d-d522459eb1ab",
   "metadata": {},
   "source": [
    "how 매개변수를 사용하여 'inner', 'outer', 'left', 'right' 방식으로 두 데이터프레임을 합치는 방법\n",
    "\n",
    "|매개변수|기능|\n",
    "|--|--|\n",
    "|'inner'| 두 데이터프레임의 'ID' 열을 비교하여 공통된 'ID' 값만 합칩니다.|\n",
    "|'outer'| 두 데이터프레임의 모든 행을 합치며,  'ID' 값이 하나라도 있는 경우에는 해당 값을,  둘 다 없는 경우에는 NaN으로 처리합니다.|\n",
    "|'left'| 첫 번째 데이터프레임 df1의 모든 행을 합칩니다.  두 데이터프레임의 'ID' 열을 비교하여 공통된 'ID' 값만 합치며, 'df1'의 모든 행은 보존됩니다.|\n",
    "|'right'| 두 번째 데이터프레임 df2의 모든 행을 합칩니다.  두 데이터프레임의 'ID' 열을 비교하여 공통된 'ID' 값만 합치며, 'df2'의 모든 행은 보존됩니다.|"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff8f6928-a1e2-4319-a8bc-2fa1a4c89d5a",
   "metadata": {},
   "source": [
    "자세한 내용을 예제를 통해서 확인해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "eec5b731-c702-4d5d-afc1-6a7289d1e3b9",
   "metadata": {},
   "source": [
    "아래의 코드는 'ID' 열을 기준으로 두 데이터프레임 합치는데,\n",
    "how 파라미터로 outer를 입력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9126a3b-4d07-483c-b156-55255827b56b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'ID' 열을 기준으로 두 데이터프레임 합치기 (outer join)\n",
    "pd.merge(df1, df2, on='ID', how='outer')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e481269-cb34-410c-814f-5f626216c6a1",
   "metadata": {},
   "source": [
    "이 경우 df1, df2의 모든 행이 누락없이 데이터 프레임에 포함하는 방식으로\n",
    "양쪽 모두에 공통으로 존재하지 않는 id를 가진 행도 포함이 되나,\n",
    "이경우 컬럼값이 매핑이 되지 않는 경우에는 NaN 값으로 채워지게 됩니다.\n",
    "예를 들어 첫번째 행의 경우 ID 1은 df1에만 존재하므로 Name 컬럼은 Alice라는 값으로 되어 있으나\n",
    "Age 값은 df2에만 있고 df1에서는 존재하지 않는 컬럼이므로 해당 값은 NaN이 들어가게 됩니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4faebf9c-0423-4d95-a8b5-2b0eb9fb3678",
   "metadata": {},
   "source": [
    "다음은 how=left 파라미터로 merge를 호출하는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdfdf09-24ba-4a48-aa7c-6d271d18c15c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'ID' 열을 기준으로 두 데이터프레임 합치기 (left join)\n",
    "pd.merge(df1, df2, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12cf75d5-0858-46ea-a538-558309c1a84a",
   "metadata": {},
   "source": [
    "위의 결과를 보면 how=left로 인자를 입력하였을 경우\n",
    "좌측편, 즉 첫번째 파라미터인 df1의 모든 행은 포함이 되고\n",
    "해당 내용을 기준으로 ID열에 매핑이 되는 df2의 행만 포함이 되게 됩니다.\n",
    "그래서 Alice, Bob 이 포함딘 행은 Age가 NaN으로 채워지게 됩니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "616865e8-26d7-409c-9f6f-f799265f862a",
   "metadata": {},
   "source": [
    "다음은 how=right 파라미터로 merge를 호출하는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766c3a2-61d3-406b-9efe-186632b7469a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'ID' 열을 기준으로 두 데이터프레임 합치기 (right join)\n",
    "pd.merge(df1, df2, on='ID', how='right')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f6bb7ed-7a72-45cc-bdc2-3a02f209d741",
   "metadata": {
    "tags": []
   },
   "source": [
    "위의 결과를 보면 how=rogjt로 인자를 입력하였을 경우\n",
    "우측편, 즉 두번째 파라미터인 df2의 모든 행은 포함이 되고\n",
    "해당 내용을 기준으로 ID열에 매핑이 되는 df1의 행만 포함이 되게 됩니다.\n",
    "그래서 ID가 5로 되어 있는 행의 경우에는 Name에 NaN으로 채워지게 됩니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbe3ee26-62cf-49c9-a01b-48291ff1a954",
   "metadata": {
    "tags": []
   },
   "source": [
    "on, left_on, right_on은 merge() 메서드에서 사용되는 매개변수로, \n",
    "두 데이터프레임을 특정 열을 기준으로 합칠 때 해당 열들을 지정하는 역할을 합니다.\n",
    "\n",
    "meger 하는 기준 컬럼의 이름이 양쪽 데이터 프레임에서 동일한 경우에는 on을 사용하면 되지만,\n",
    "\n",
    "두 데이터프레임이 서로 다른 열 이름을 가지고 있을 때는\n",
    "left_on, right_on 매개변수를 사용하여 왼쪽 데이터 프레임에서의 기준열과\n",
    "오른쪽 데이터프레임에서의 기준 열을 각각 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040671c5-bdc3-452e-9010-7334166d6789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "on, left_on, right_on은 merge() 메서드에서 사용되는 매개변수로, \n",
    "두 데이터프레임을 특정 열을 기준으로 합칠 때 해당 열들을 지정하는 역할을 합니다.\n",
    "left_on, right_on 매개변수를 사용하여 \n",
    "두 데이터프레임이 서로 다른 열 이름을 가지고 있을 때도 쉽게 합치는 것이 가능합니다.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 생성\n",
    "data1 = {\n",
    "    'ID': [1, 2, 3],\n",
    "    'Age': [25, 30, 35]\n",
    "}\n",
    "\n",
    "data2 = {\n",
    "    'StudentID': [2, 3, 4],\n",
    "    'Credit': [25, 30, 35]\n",
    "}\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13a9ac-cbea-4694-8f20-e12b77fb31b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b334b53e-f717-4e26-8d11-c00d969887dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dee0b09b-d593-4285-be7c-e64443ff0652",
   "metadata": {},
   "source": [
    "df1의 'ID'와 df2의 'StudentID' 열을 기준으로 두 데이터프레임 합치기 위해서는\n",
    "left_on 에서는 첫번째 파라미터 즉 좌측이 되는 데이터프레임의 기준열인 \"ID\"를 넣어주고\n",
    "right_ont 에서는 두번째 파라미터 즉 우측이 되는 데이터프레임의 기준열인 \"StudentID\"를 넣어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22100665-b1b4-4dc8-bfa1-95ff1325a47a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'ID'와 'StudentID' 열을 기준으로 두 데이터프레임 합치기\n",
    "pd.merge(df1, df2, left_on='ID', right_on='StudentID')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c159697-6a9e-4607-9998-a1d1a03ae1aa",
   "metadata": {},
   "source": [
    "위의 코드의 실행결과를 보면 df1의 ID와 df2의 studentID가 일치할 경우 \n",
    "데이터를 병합한 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c3e56fe-398b-4216-8316-e1e0ad5e4be0",
   "metadata": {},
   "source": [
    "이상으로 이번강의를 마치도록 하겠습니다.\n",
    "수고하셨습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dab76a-d99a-4218-8a15-cfa7d085d117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
